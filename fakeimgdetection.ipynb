{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg06ZmKz1X2JRhjU3ZpeiP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saniya2272/fakevsreal/blob/main/fakeimgdetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pjrbNBSLhUBs"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import seaborn as sns\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session() #clean session"
      ],
      "metadata": {
        "id": "si_-nNtvtRn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "main_path = '/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n",
        "\n",
        "train_dir = os.path.join(main_path, 'train')\n",
        "valid_dir = os.path.join(main_path, 'valid')\n",
        "test_dir = os.path.join(main_path, 'test')"
      ],
      "metadata": {
        "id": "FwVnNPmiqfwa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train_dir Subfolders: \", os.listdir(train_dir))\n",
        "print(\"Valid_dir Subfolders: \", os.listdir(valid_dir))\n",
        "print(\"Test_dir Subfolders: \", os.listdir(test_dir))"
      ],
      "metadata": {
        "id": "5LYthFOy78rL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_df = {\n",
        "    \"folder\":[],\n",
        "    \"image_path\":[],\n",
        "    \"label\":[]\n",
        "}\n",
        "\n",
        "for folder in os.listdir(main_path): #iterate on each train, valid and test folder\n",
        "    for label in os.listdir(main_path + \"/\" + folder): #iterate on fake and real folders (labels)\n",
        "        for img in glob.glob(main_path + \"/\" + folder + \"/\" + label + \"/*.jpg\"):\n",
        "            images_df[\"folder\"].append(folder)\n",
        "            images_df[\"image_path\"].append(img)\n",
        "            images_df[\"label\"].append(label)"
      ],
      "metadata": {
        "id": "wLoiAk6z8Cht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_df = pd.DataFrame(images_df)"
      ],
      "metadata": {
        "id": "Sltz-7szXoG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_df"
      ],
      "metadata": {
        "id": "upWELNBeXq5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_grouped_df = images_df[images_df['label'] == \"real\"].groupby('folder')\n",
        "fake_grouped_df = images_df[images_df['label'] == \"fake\"].groupby('folder')"
      ],
      "metadata": {
        "id": "O8rvU9HJXtQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_grouped_df.size()"
      ],
      "metadata": {
        "id": "TUGgQ0aqXv1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_grouped_df.size()"
      ],
      "metadata": {
        "id": "KuZ4nj7UXx7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "                                  rescale=1./255.,\n",
        "                                  horizontal_flip=True,\n",
        "                                  )\n",
        "\n",
        "image_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255.)"
      ],
      "metadata": {
        "id": "D_8rOtCqX1lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = image_train_gen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=64,\n",
        "    class_mode='binary',\n",
        ")\n",
        "\n",
        "valid_ds = image_gen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=64,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_ds = image_gen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=64,\n",
        "    class_mode='binary',\n",
        "    shuffle=False) #shuffle disabled"
      ],
      "metadata": {
        "id": "91KZU63eX4LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(img, label):\n",
        "    plt.figure(figsize=[12, 12])\n",
        "    for i in range(16):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(img[i])\n",
        "        plt.axis('off')\n",
        "        if label[i] == 0:\n",
        "            plt.title(\"Fake\")\n",
        "        else:\n",
        "            plt.title(\"Real\")"
      ],
      "metadata": {
        "id": "G4eo2rmZYAY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img,lbl = next(train_ds)\n",
        "plot_images(img,lbl)\n"
      ],
      "metadata": {
        "id": "o40O1JoYYDlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img, label in train_ds:\n",
        "    print(\"Values: \", img[0])\n",
        "    print(\"Label: \", label[0])\n",
        "    break"
      ],
      "metadata": {
        "id": "qtyTHuzdYGFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img, label in train_ds:\n",
        "    print(img.shape)\n",
        "    print(label.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "wMVHA23xYIWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.class_indices"
      ],
      "metadata": {
        "id": "0yIPfWFbYK3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (256, 256, 3) #define the input shape of our data"
      ],
      "metadata": {
        "id": "TAT1kHH3YNof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the model's architecture and compile it\n",
        "def get_model(input_shape):\n",
        "\n",
        "    input = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    densenet = tf.keras.applications.DenseNet121( weights=\"imagenet\", include_top=False, input_tensor = input)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(densenet.output)\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid')(x) #binary classification\n",
        "\n",
        "    model = tf.keras.Model(densenet.input, output)\n",
        "\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "vsmiuaVQYRPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = get_model(input_shape)\n",
        "\n",
        "model_ft.summary()"
      ],
      "metadata": {
        "id": "3XggBuh7YWEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model_ft, show_shapes=True)"
      ],
      "metadata": {
        "id": "QVJtXSCyYXIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = \"model_cp.h5\"\n",
        "\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min', #minimize the loss value\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "f8ZjSL7rYZuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                     patience=5,\n",
        "                                                     restore_best_weights=True,\n",
        "                                                    )"
      ],
      "metadata": {
        "id": "wQTJOjofYbup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                                 factor=0.2,\n",
        "                                                 patience=3)"
      ],
      "metadata": {
        "id": "2gvkExQsYeZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_ft = model_ft.fit(train_ds,\n",
        "                       epochs = 10,\n",
        "                       validation_data = valid_ds,\n",
        "                       callbacks=[checkpoint_cb, early_stopping_cb, reduce_lr])"
      ],
      "metadata": {
        "id": "AXCGbaUjYhog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history_ft.history['accuracy'])\n",
        "plt.plot(history_ft.history['val_accuracy'])\n",
        "plt.title('Model Accuracy (training & valid)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Valid'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history_ft.history['loss'])\n",
        "plt.plot(history_ft.history['val_loss'])\n",
        "plt.title('Model Loss (training & val)')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Valid'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8_yw2duTYkT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model_ft.evaluate(test_ds)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "id": "vo0bRtcFYnCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model(input_shape)\n",
        "\n",
        "# Restore the weights\n",
        "model.load_weights('/content/drive/MyDrive/model_cp.h5')\n"
      ],
      "metadata": {
        "id": "U8SoekBGYq0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OE2IiBgfYsby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "id": "AVQmUOHUYwEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#real example\n",
        "test_image = tf.keras.preprocessing.image.load_img('/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake/test/real/00343.jpg', target_size=(256, 256, 3))\n",
        "plt.imshow(test_image)\n",
        "\n",
        "\n",
        "test_image_arr = tf.keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_arr = np.expand_dims(test_image, axis=0)\n",
        "test_image_arr = test_image_arr/255.\n",
        "\n",
        "\n",
        "result = model.predict(test_image_arr)\n",
        "\n",
        "plt.title(f\"This image is {100 * (1 - result[0][0]):.2f}% Fake and {100 * result[0][0]:.2f}% Real.\")\n"
      ],
      "metadata": {
        "id": "4Cpjge5bYw7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = tf.keras.preprocessing.image.load_img('/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake/test/fake/00V5CZZSSO.jpg', target_size=(256, 256, 3))\n",
        "plt.imshow(test_image)\n",
        "\n",
        "#fake example\n",
        "test_image_arr = tf.keras.preprocessing.image.img_to_array(test_image)\n",
        "test_image_arr = np.expand_dims(test_image, axis=0)\n",
        "test_image_arr = test_image_arr/255.\n",
        "\n",
        "\n",
        "result = model.predict(test_image_arr)\n",
        "\n",
        "plt.title(f\"This image is {100 * (1 - result[0][0]):.2f}% Fake and {100 * result[0][0]:.2f}% Real.\")"
      ],
      "metadata": {
        "id": "tKmS6wQYYzKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have defined your model as 'model'\n",
        "predicted_labels = model.predict(test_ds)"
      ],
      "metadata": {
        "id": "TYtAQhE9Y2Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = test_ds.classes"
      ],
      "metadata": {
        "id": "UFvw7mdPY41n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8,5))\n",
        "sns.heatmap(metrics.confusion_matrix(true_labels, predicted_labels.round()), annot = True,fmt=\"d\",cmap = \"Greens\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6UlqdIsSY7Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.accuracy_score(true_labels, predicted_labels.round())"
      ],
      "metadata": {
        "id": "FaDmw9v2Y-DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, _ = metrics.roc_curve(true_labels,  predicted_labels)\n",
        "auc = metrics.roc_auc_score(true_labels, predicted_labels)\n",
        "\n",
        "#create ROC curve\n",
        "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vHcrlFAeZAgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import keras"
      ],
      "metadata": {
        "id": "qJIAd8ewZDD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.utils.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.utils.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer as well as the output predictions\n",
        "    grad_model = keras.models.Model(\n",
        "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # This is the gradient of the output neuron (top predicted or chosen)\n",
        "    # with regard to the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    # then sum all the channels to obtain the heatmap class activation\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()"
      ],
      "metadata": {
        "id": "NWRtEwPJZFJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.5):\n",
        "    # Load the original image\n",
        "    img = keras.utils.load_img(img_path)\n",
        "    img = keras.utils.img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
        "\n",
        "    # Save the superimposed image\n",
        "    superimposed_img.save(cam_path)\n",
        "\n",
        "    # Display Grad CAM\n",
        "    display(Image(cam_path))"
      ],
      "metadata": {
        "id": "S0gO-RqQZIu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the names of all layers in the model.\n",
        "for idx in range(len(model.layers)):\n",
        "  print(model.get_layer(index = idx).name)"
      ],
      "metadata": {
        "id": "i8GvsXcZZK09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img_size = (256, 256)\n",
        "\n",
        "\n",
        "last_conv_layer_name = \"conv5_block16_1_conv\"\n",
        "\n",
        "img_path = '/content/02NUKFGPSJ.jpg'\n",
        "\n",
        "test_image = tf.keras.preprocessing.image.load_img(img_path, target_size=(256, 256, 3))\n",
        "plt.imshow(test_image)\n",
        "\n",
        "img = tf.keras.preprocessing.image.img_to_array(test_image)\n",
        "img = np.expand_dims(img, axis=0)\n",
        "img = img/255.\n"
      ],
      "metadata": {
        "id": "RvKXETl3ZN0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove last layer's softmax\n",
        "model.layers[-1].activation = None\n",
        "\n",
        "# Print what the top predicted class is\n",
        "preds = model.predict(img)\n",
        "print(\"Predicted:\", preds)\n",
        "\n",
        "# Generate class activation heatmap\n",
        "heatmap = make_gradcam_heatmap(img, model, \"conv5_block16_1_conv\")\n",
        "heatmap_2 = make_gradcam_heatmap(img, model, \"conv5_block16_2_conv\")\n",
        "heatmap_3 = make_gradcam_heatmap(img, model, \"conv5_block15_1_conv\")\n",
        "heatmap_4 = make_gradcam_heatmap(img, model, \"conv5_block14_1_conv\")\n",
        "heatmap_5 = make_gradcam_heatmap(img, model, \"conv5_block13_2_conv\")\n",
        "\n",
        "# Display heatmap\n",
        "plt.matshow(heatmap)\n",
        "plt.matshow(heatmap_2)\n",
        "plt.matshow(heatmap_3)\n",
        "plt.matshow(heatmap_4)\n",
        "plt.matshow(heatmap_5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lG7DsUydZQad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_and_display_gradcam(img_path, heatmap)\n",
        "save_and_display_gradcam(img_path, heatmap_2)\n",
        "save_and_display_gradcam(img_path, heatmap_3)\n",
        "save_and_display_gradcam(img_path, heatmap_4)\n",
        "save_and_display_gradcam(img_path, heatmap_5)"
      ],
      "metadata": {
        "id": "WxmSPgpfZTlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the model's architecture and compile it\n",
        "def get_xcp_model(input_shape):\n",
        "\n",
        "    input = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    xception = tf.keras.applications.Xception( weights=\"imagenet\", include_top=False, input_tensor = input)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(xception.output)\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid')(x) #binary classification\n",
        "\n",
        "    model = tf.keras.Model(xception.input, output)\n",
        "\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "oWQ8zfaCZXBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xcp_model = get_xcp_model(input_shape)\n",
        "\n",
        "tf.keras.utils.plot_model(xcp_model, show_shapes=True)"
      ],
      "metadata": {
        "id": "SnrALyNiZZdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath_xcp = \"model_xcp.h5\"\n",
        "\n",
        "checkpoint_xcp = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath_xcp,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min', #minimize the loss value\n",
        "    save_best_only=True)\n",
        "\n",
        "early_stopping_xcp = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                     patience=5,\n",
        "                                                     restore_best_weights=True,\n",
        "                                                    )\n",
        "\n",
        "reduce_lr_xcp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                                 factor=0.2,\n",
        "                                                 patience=3)"
      ],
      "metadata": {
        "id": "PvjaiGH0Zbyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_ft = model_ft.fit(train_ds,\n",
        "                       epochs = 10,\n",
        "                       validation_data = valid_ds,\n",
        "                       callbacks=[checkpoint_xcp, early_stopping_xcp, reduce_lr_xcp])"
      ],
      "metadata": {
        "id": "NehtVi1TZhFx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}